# üö¢ Titanic Survival Prediction - Multilayer Perceptron (MLP)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Status](https://img.shields.io/badge/Status-Completed-success)
![License](https://img.shields.io/badge/License-MIT-green)

## üìã Sobre o Projeto

Este projeto consiste na implementa√ß√£o de um modelo preditivo baseado em **Redes Neurais Artificiais (Multilayer Perceptron - MLP)** para estimar a probabilidade de sobreviv√™ncia de passageiros do naufr√°gio do Titanic.

O desenvolvimento utiliza o famoso banco de dados dispon√≠vel no [Kaggle](https://www.kaggle.com/c/titanic) e segue um rigoroso pipeline de ci√™ncia de dados, desde a an√°lise explorat√≥ria at√© a otimiza√ß√£o de hiperpar√¢metros e valida√ß√£o em dados de teste.

## üéØ Objetivos

O foco principal deste trabalho √© a aplica√ß√£o pr√°tica de conceitos de Deep Learning com as seguintes metas espec√≠ficas:

1. **EDA (An√°lise Explorat√≥ria de Dados):** Compreens√£o das vari√°veis e padr√µes de sobreviv√™ncia.
2. **Divis√£o Estrat√©gica dos Dados:** Separa√ß√£o do dataset em **50% Treinamento, 25% Valida√ß√£o e 25% Teste**.
3. **Pr√©-processamento:** Limpeza, imputa√ß√£o de nulos e codifica√ß√£o de vari√°veis categ√≥ricas.
4. **Balanceamento de Classes:** Aplica√ß√£o de t√©cnicas de **Oversampling** na classe minorit√°ria do conjunto de treino.
5. **Modelagem MLP:** Constru√ß√£o e treinamento de redes neurais.
6. **Otimiza√ß√£o:** Ajuste de hiperpar√¢metros baseado em m√©tricas de valida√ß√£o.
7. **Avalia√ß√£o Final:** Teste do melhor modelo em dados nunca vistos.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python
* **Manipula√ß√£o de Dados:** Pandas, NumPy
* **Visualiza√ß√£o:** Matplotlib, Seaborn
* **Machine Learning/Deep Learning:** Scikit-learn, TensorFlow/Keras (ou PyTorch - *ajuste conforme seu c√≥digo*)

## üìä Metodologia e Pipeline

### 1. An√°lise Explorat√≥ria (EDA)
Foi realizada uma an√°lise profunda para entender correla√ß√µes, como a taxa de sobreviv√™ncia por g√™nero, classe socioecon√¥mica e idade.

### 2. Divis√£o do Dataset
Diferente da divis√£o padr√£o 70/30 ou 80/20, este projeto seguiu a seguinte especifica√ß√£o rigorosa:
* **Treinamento (50%):** Usado para ajustar os pesos da rede.
* **Valida√ß√£o (25%):** Usado para tunar hiperpar√¢metros e evitar overfitting durante o treino.
* **Teste (25%):** Usado exclusivamente para a avalia√ß√£o final do modelo.

### 3. Tratamento de Dados
* Normaliza√ß√£o de vari√°veis num√©ricas (StandardScaler/MinMaxScaler).
* One-Hot Encoding para vari√°veis categ√≥ricas.
* Tratamento de valores ausentes (Missing Values).

### 4. Oversampling
Identificou-se desbalanceamento nas classes (mais v√≠timas do que sobreviventes). Foi aplicada t√©cnica de oversampling (ex: SMOTE ou RandomOverSampler) apenas nos dados de **treinamento** para garantir que o modelo aprenda padr√µes de ambas as classes sem vi√©s.

### 5. Arquitetura da MLP
O modelo base consiste em um Perceptron Multicamadas (Feedforward Neural Network).


* **Camada de Entrada:** Compat√≠vel com o n√∫mero de features processadas.
* **Camadas Ocultas:** Testadas com diferentes fun√ß√µes de ativa√ß√£o (ReLU, Sigmoid, Tanh).
* **Camada de Sa√≠da:** Neur√¥nio √∫nico com ativa√ß√£o Sigmoid (classifica√ß√£o bin√°ria).

## üìä An√°lise Explorat√≥ria (EDA)

Antes da modelagem, foram analisadas as correla√ß√µes entre vari√°veis.

### Mapa de Calor (Correla√ß√£o)
A an√°lise de correla√ß√£o mostrou que `SibSp` e `Parch` possuem forte rela√ß√£o, justificando a cria√ß√£o da feature `Family`.
![Heatmap de Correla√ß√£o](assets/heatmap.png)

### Sobreviv√™ncia por G√™nero e Porto
Notou-se uma maior taxa de sobreviv√™ncia entre mulheres e passageiros que embarcaram em portos espec√≠ficos.
<div style="display: flex; justify-content: space-between;">
  <img src="assets/sexo_sobrevivencia.png" alt="Sexo x Sobreviv√™ncia" width="45%">
  <img src="assets/porto_sobrevivencia.png" alt="Porto x Sobreviv√™ncia" width="45%">
</div>

---

## üìà Resultados do Modelo

Ap√≥s a otimiza√ß√£o dos hiperpar√¢metros (GridSearch), o melhor modelo MLP obteve o seguinte desempenho na classifica√ß√£o dos passageiros do conjunto de teste:

| M√©trica | Resultado |
| :--- | :--- |
| Acur√°cia | 83.33% |
| Precis√£o | 0.84 |
| Recall | 0.69 |
| F1-Score | 0.76 |

### Matriz de Confus√£o
A matriz abaixo detalha os acertos e erros do modelo final.
![Matriz de Confus√£o Final](assets/matriz_confusao_final.png)



## üöÄ Como Executar

1. Clone o reposit√≥rio:
   ```bash
   git clone [https://github.com/SEU_USUARIO/NOME_DO_REPO.git](https://github.com/SEU_USUARIO/NOME_DO_REPO.git)

   Instale as depend√™ncias:

    pip install -r requirements.txt

   Execute o Notebook:
    Projeto_Machine_Learning(MLP).ipynb
   ```
# ‚úíÔ∏è Autor
Alisson da Silva Bernadino - LinkedIn https://www.linkedin.com/in/alisson-da-silva-bernadino-6535b3318/

